{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15 亿参数 GPT2 中文预训练模型  ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 -m pip install -U tqdm\n",
        "!git clone https://github.com/imcaspar/gpt2-ml\n",
        "%cd /content/gpt2-ml"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from apiclient.http import MediaIoBaseDownload\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os  \n",
        "import io\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "STEP_NUMBER = 100000\n",
        "model_type = 'mega'\n",
        "model_path = '/content/gpt2-ml/models'\n",
        "model_dir = os.path.join(model_path, model_type)\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "local_file_ids = ['1n_5-tgPpQ1gqbyLPbP1PwiFi2eo7SWw_']\n",
        "local_filenames = ['.data-00000-of-00001']\n",
        "for ext, id_ in zip(local_filenames, local_file_ids):\n",
        "    ext = str(STEP_NUMBER) + ext\n",
        "    filename = '%s/%s/model.ckpt-%s' % (model_path, model_type, ext)\n",
        "    request = drive_service.files().get_media(fileId=id_)\n",
        "    with open(filename, 'wb') as f:\n",
        "      downloader = MediaIoBaseDownload(f, request, chunksize=100*1024*1024)\n",
        "      done = False\n",
        "      pbar = tqdm(total=100, desc='%s' % ext)\n",
        "      progress = 0\n",
        "      while done is False:\n",
        "        status, done = downloader.next_chunk()\n",
        "        new_progress = int(status.progress() * 100)\n",
        "        pbar.update(new_progress - progress)\n",
        "        progress = new_progress\n",
        "      pbar.close()\n",
        "\n",
        "!wget -q --show-progress https://github.com/imcaspar/gpt2-ml/releases/download/v0.5/model.ckpt-100000.index -P models/mega\n",
        "!wget -q --show-progress https://github.com/imcaspar/gpt2-ml/releases/download/v0.5/model.ckpt-100000.meta -P models/mega"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git fetch && git checkout dev && git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#THis option lets you type from colab, but you can't enter new lines\n",
        "!PYTHONPATH=$(pwd) python3 scripts/contextual_generate_cli.py -model_config_fn configs/mega.json -model_ckpt models/mega/model.ckpt-100000 -samples 10"
      ]
    }
  ]
}